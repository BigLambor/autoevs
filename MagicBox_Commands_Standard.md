# MagicBox è„šæœ¬æ ‡å‡†åŒ–å‘½ä»¤å‚è€ƒ

## ğŸ“‹ æ¦‚è¿°

æ‰€æœ‰å‘½ä»¤é»˜è®¤é…ç½®ï¼š
- **Pythonè§£é‡Šå™¨**ï¼š`python3`
- **ç¯å¢ƒ**ï¼š`prod`  
- **å‘½åç©ºé—´**ï¼š`ns1`

## ğŸ” ç›‘æ§è„šæœ¬ (Monitor)

### 1. Hive ç›‘æ§è„šæœ¬
**è·¯å¾„**: `magicbox/monitor/hive/hive_monitor.py`

#### åŸºæœ¬å‘½ä»¤æ ¼å¼
```bash
python3 -m magicbox.monitor.hive.hive_monitor --run=<å‡½æ•°å> [é€‰é¡¹]
```

#### æ‰§è¡Œå¼•æ“æ”¯æŒ
æ”¯æŒæŒ‡å®šHiveæ‰§è¡Œå¼•æ“ï¼Œæé«˜æŸ¥è¯¢æ€§èƒ½ï¼š
- `mr`: MapReduceå¼•æ“ï¼ˆé»˜è®¤ï¼Œç¨³å®šæ€§å¥½ï¼‰
- `tez`: Tezå¼•æ“ï¼ˆæ€§èƒ½è¾ƒå¥½ï¼Œé€‚åˆå¤æ‚æŸ¥è¯¢ï¼‰
- `spark`: Sparkå¼•æ“ï¼ˆå†…å­˜è®¡ç®—ï¼Œé€‚åˆè¿­ä»£è®¡ç®—ï¼‰

#### å¯ç”¨å‡½æ•°åŠæ ‡å‡†å‘½ä»¤
```bash
# åˆ›å»ºæµ‹è¯•è¡¨
python3 -m magicbox.monitor.hive.hive_monitor --run=create_test_table --env=prod

# åˆ é™¤æµ‹è¯•è¡¨
python3 -m magicbox.monitor.hive.hive_monitor --run=drop_test_table --env=prod

# æ·»åŠ æµ‹è¯•åˆ†åŒº
python3 -m magicbox.monitor.hive.hive_monitor --run=add_test_partition --env=prod

# åŠ è½½æµ‹è¯•æ•°æ®
python3 -m magicbox.monitor.hive.hive_monitor --run=load_test_data --env=prod

# ç»Ÿè®¡æµ‹è¯•æ•°æ®
python3 -m magicbox.monitor.hive.hive_monitor --run=count_test_data --env=prod

# æ£€æŸ¥è¡¨å­˜å‚¨æ ¼å¼
python3 -m magicbox.monitor.hive.hive_monitor --run=check_table_storage --env=prod

# æ£€æŸ¥åˆ†åŒºå¥åº·çŠ¶æ€
python3 -m magicbox.monitor.hive.hive_monitor --run=check_partition_health --env=prod

# æ£€æŸ¥æ•°æ®è´¨é‡
python3 -m magicbox.monitor.hive.hive_monitor --run=check_data_quality --env=prod

# æ£€æŸ¥æŸ¥è¯¢æ€§èƒ½
python3 -m magicbox.monitor.hive.hive_monitor --run=check_query_performance --env=prod

# æ£€æŸ¥æ‰§è¡Œå¼•æ“è®¾ç½®
python3 -m magicbox.monitor.hive.hive_monitor --run=check_execution_engine --env=prod

# æ£€æŸ¥è¡¨å…ƒæ•°æ®
python3 -m magicbox.monitor.hive.hive_monitor --run=check_table_metadata --env=prod

# è¿è¡Œæ‰€æœ‰æ£€æŸ¥
python3 -m magicbox.monitor.hive.hive_monitor --run=run_all --env=prod

# å¯ç”¨è°ƒè¯•æ¨¡å¼
python3 -m magicbox.monitor.hive.hive_monitor --run=check_table_storage --env=prod --debug

# æŒ‡å®šæ‰§è¡Œå¼•æ“ç¤ºä¾‹
python3 -m magicbox.monitor.hive.hive_monitor --run=run_all --env=prod --engine=tez
python3 -m magicbox.monitor.hive.hive_monitor --run=check_query_performance --env=prod --engine=spark
python3 -m magicbox.monitor.hive.hive_monitor --run=check_table_storage --env=prod --engine=mr
```

#### å‚æ•°è¯´æ˜
- `--run`: è¦æ‰§è¡Œçš„å‡½æ•°åï¼ˆå¿…éœ€ï¼‰
- `--env`: ç¯å¢ƒåç§°ï¼Œå¯é€‰å€¼ï¼šdev/test/prodï¼ˆå¯é€‰ï¼Œé»˜è®¤prodï¼‰
- `--engine`: Hiveæ‰§è¡Œå¼•æ“ï¼Œå¯é€‰å€¼ï¼šmr/tez/sparkï¼ˆå¯é€‰ï¼‰
- `--debug`: å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆå¯é€‰ï¼‰

---

## ğŸ“Š å®šæœŸä»»åŠ¡è„šæœ¬ (Periodic Tasks)

### 2. YARN åº”ç”¨çŠ¶æ€é‡‡é›†
**è·¯å¾„**: `magicbox/periodic/yarn/collect_yarn_apps.py`

#### æ ‡å‡†å‘½ä»¤
```bash
# ç”Ÿäº§ç¯å¢ƒé‡‡é›†
python3 -m magicbox.periodic.yarn.collect_yarn_apps --cluster_name=hadoop-cluster --env=prod

# è‡ªå®šä¹‰é›†ç¾¤åç§°
python3 -m magicbox.periodic.yarn.collect_yarn_apps --cluster_name=my-hadoop-cluster --env=prod
```

#### å‚æ•°è¯´æ˜
- `--cluster_name`: é›†ç¾¤åç§°ï¼ˆå¿…éœ€ï¼‰
- `--env`: ç¯å¢ƒåç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤prodï¼‰

---

### 3. YARN åº”ç”¨å¿«ç…§é‡‡é›†
**è·¯å¾„**: `magicbox/periodic/yarn/collect_yarn_app_snapshots.py`

#### æ ‡å‡†å‘½ä»¤
```bash
# é‡‡é›†æ‰€æœ‰çŠ¶æ€çš„åº”ç”¨
python3 -m magicbox.periodic.yarn.collect_yarn_app_snapshots --cluster_name=hadoop-cluster --env=prod

# é‡‡é›†æŒ‡å®šçŠ¶æ€çš„åº”ç”¨
python3 -m magicbox.periodic.yarn.collect_yarn_app_snapshots --cluster_name=hadoop-cluster --env=prod --states=RUNNING,FINISHED

# é‡‡é›†å¤±è´¥åº”ç”¨
python3 -m magicbox.periodic.yarn.collect_yarn_app_snapshots --cluster_name=hadoop-cluster --env=prod --states=FAILED,KILLED
```

#### å‚æ•°è¯´æ˜
- `--cluster_name`: é›†ç¾¤åç§°ï¼ˆå¿…éœ€ï¼‰
- `--env`: ç¯å¢ƒåç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤prodï¼‰
- `--states`: è¦é‡‡é›†çš„åº”ç”¨çŠ¶æ€ï¼Œå¤šä¸ªçŠ¶æ€ç”¨é€—å·åˆ†éš”ï¼ˆå¯é€‰ï¼‰
  - å¯ç”¨çŠ¶æ€ï¼šNEW, NEW_SAVING, SUBMITTED, ACCEPTED, RUNNING, FINISHED, FAILED, KILLED

---

### 4. YARN é˜Ÿåˆ—èµ„æºé‡‡é›†
**è·¯å¾„**: `magicbox/periodic/yarn/collect_yarn_queues.py`

#### æ ‡å‡†å‘½ä»¤
```bash
# é‡‡é›†é˜Ÿåˆ—èµ„æºä¿¡æ¯
python3 -m magicbox.periodic.yarn.collect_yarn_queues --cluster_name=hadoop-cluster --env=prod

# æŒ‡å®šä¸åŒé›†ç¾¤
python3 -m magicbox.periodic.yarn.collect_yarn_queues --cluster_name=spark-cluster --env=prod
```

#### å‚æ•°è¯´æ˜
- `--cluster_name`: é›†ç¾¤åç§°ï¼ˆå¿…éœ€ï¼‰
- `--env`: ç¯å¢ƒåç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤prodï¼‰

---

### 5. YARN èµ„æºç®¡ç†é‡‡é›†
**è·¯å¾„**: `magicbox/periodic/yarn/collect_yarn_resources.py`

#### æ ‡å‡†å‘½ä»¤
```bash
# é‡‡é›†YARNç®¡ç†èµ„æºä¿¡æ¯
python3 -m magicbox.periodic.yarn.collect_yarn_resources --cluster_name=hadoop-cluster --env=prod

# æŒ‡å®šä¸åŒé›†ç¾¤
python3 -m magicbox.periodic.yarn.collect_yarn_resources --cluster_name=my-cluster --env=prod
```

#### å‚æ•°è¯´æ˜
- `--cluster_name`: é›†ç¾¤åç§°ï¼ˆå¿…éœ€ï¼‰
- `--env`: ç¯å¢ƒåç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤prodï¼‰

---

### 6. HDFS æ¦‚è§ˆä¿¡æ¯é‡‡é›†
**è·¯å¾„**: `magicbox/periodic/hdfs/collect_hdfs_overview.py`

#### æ ‡å‡†å‘½ä»¤
```bash
# æ ‡å‡†é‡‡é›†ï¼ˆä½¿ç”¨é»˜è®¤ns1ï¼‰
python3 -m magicbox.periodic.hdfs.collect_hdfs_overview --cluster_name=hadoop-cluster --ns_name=ns1 --env=prod

# æŒ‡å®šä¸åŒå‘½åç©ºé—´
python3 -m magicbox.periodic.hdfs.collect_hdfs_overview --cluster_name=hadoop-cluster --ns_name=ns2 --env=prod

# æŒ‡å®šä¸åŒé›†ç¾¤å’Œå‘½åç©ºé—´
python3 -m magicbox.periodic.hdfs.collect_hdfs_overview --cluster_name=prod-cluster --ns_name=ns1 --env=prod
```

#### å‚æ•°è¯´æ˜
- `--cluster_name`: é›†ç¾¤åç§°ï¼ˆå¿…éœ€ï¼‰
- `--ns_name`: å‘½åç©ºé—´åç§°ï¼ˆå¿…éœ€ï¼Œé»˜è®¤ns1ï¼‰
- `--env`: ç¯å¢ƒåç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤prodï¼‰

---

### 7. Hive å­˜å‚¨ä¿¡æ¯é‡‡é›†
**è·¯å¾„**: `magicbox/periodic/hdfs/collect_hive_storage.py`

#### æ ‡å‡†å‘½ä»¤
```bash
# æ ‡å‡†é‡‡é›†ï¼ˆä½¿ç”¨é»˜è®¤ns1ï¼‰
python3 -m magicbox.periodic.hdfs.collect_hive_storage --cluster_name=hadoop-cluster --ns_name=ns1 --env=prod

# æŒ‡å®šä¸åŒå‘½åç©ºé—´
python3 -m magicbox.periodic.hdfs.collect_hive_storage --cluster_name=hadoop-cluster --ns_name=ns2 --env=prod

# æŒ‡å®šä¸åŒé›†ç¾¤
python3 -m magicbox.periodic.hdfs.collect_hive_storage --cluster_name=prod-cluster --ns_name=ns1 --env=prod
```

#### å‚æ•°è¯´æ˜
- `--cluster_name`: é›†ç¾¤åç§°ï¼ˆå¿…éœ€ï¼‰
- `--ns_name`: å‘½åç©ºé—´åç§°ï¼ˆå¿…éœ€ï¼Œé»˜è®¤ns1ï¼‰
- `--env`: ç¯å¢ƒåç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤prodï¼‰

---

## ğŸ”„ æ‰¹é‡æ‰§è¡Œè„šæœ¬

### æ ‡å‡†æ‰¹é‡æ‰§è¡Œè„šæœ¬
```bash
#!/bin/bash
# run_all_magicbox.sh - æ‰¹é‡æ‰§è¡Œæ‰€æœ‰MagicBoxå®šæœŸä»»åŠ¡

# é»˜è®¤é…ç½®
ENV="prod"
CLUSTER_NAME="hadoop-cluster"
NS_NAME="ns1"

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
  case $1 in
    --env)
      ENV="$2"
      shift 2
      ;;
    --cluster)
      CLUSTER_NAME="$2"
      shift 2
      ;;
    --ns)
      NS_NAME="$2"
      shift 2
      ;;
    *)
      echo "æœªçŸ¥å‚æ•°: $1"
      echo "ç”¨æ³•: $0 [--env prod] [--cluster hadoop-cluster] [--ns ns1]"
      exit 1
      ;;
  esac
done

echo "=== MagicBox æ‰¹é‡æ‰§è¡Œå¼€å§‹ ==="
echo "ç¯å¢ƒ: $ENV"
echo "é›†ç¾¤: $CLUSTER_NAME"
echo "å‘½åç©ºé—´: $NS_NAME"
echo "==============================="

# YARN ç›¸å…³é‡‡é›†
echo "ğŸ”„ æ‰§è¡Œ YARN ç›¸å…³é‡‡é›†ä»»åŠ¡..."
python3 -m magicbox.periodic.yarn.collect_yarn_apps --cluster_name=$CLUSTER_NAME --env=$ENV
python3 -m magicbox.periodic.yarn.collect_yarn_app_snapshots --cluster_name=$CLUSTER_NAME --env=$ENV
python3 -m magicbox.periodic.yarn.collect_yarn_queues --cluster_name=$CLUSTER_NAME --env=$ENV
python3 -m magicbox.periodic.yarn.collect_yarn_resources --cluster_name=$CLUSTER_NAME --env=$ENV

# HDFS ç›¸å…³é‡‡é›†
echo "ğŸ”„ æ‰§è¡Œ HDFS ç›¸å…³é‡‡é›†ä»»åŠ¡..."
python3 -m magicbox.periodic.hdfs.collect_hdfs_overview --cluster_name=$CLUSTER_NAME --ns_name=$NS_NAME --env=$ENV
python3 -m magicbox.periodic.hdfs.collect_hive_storage --cluster_name=$CLUSTER_NAME --ns_name=$NS_NAME --env=$ENV

# Hive ç›‘æ§
echo "ğŸ”„ æ‰§è¡Œ Hive ç›‘æ§ä»»åŠ¡..."
python3 -m magicbox.monitor.hive.hive_monitor --run=run_all --env=$ENV

echo "âœ… æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼"
```

### ä½¿ç”¨æ‰¹é‡è„šæœ¬
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆprodç¯å¢ƒï¼Œhadoop-clusteré›†ç¾¤ï¼Œns1å‘½åç©ºé—´ï¼‰
chmod +x run_all_magicbox.sh
./run_all_magicbox.sh

# è‡ªå®šä¹‰é…ç½®
./run_all_magicbox.sh --env prod --cluster my-cluster --ns ns2

# ä»…æŒ‡å®šé›†ç¾¤åç§°
./run_all_magicbox.sh --cluster production-cluster
```

---

## ğŸ› ï¸ å¸¸ç”¨ç»„åˆå‘½ä»¤

### å®Œæ•´çš„ç³»ç»Ÿå¥åº·æ£€æŸ¥
```bash
# 1. HDFSå¥åº·æ£€æŸ¥
python3 -m magicbox.periodic.hdfs.collect_hdfs_overview --cluster_name=hadoop-cluster --ns_name=ns1 --env=prod

# 2. YARNèµ„æºæ£€æŸ¥
python3 -m magicbox.periodic.yarn.collect_yarn_resources --cluster_name=hadoop-cluster --env=prod

# 3. Hiveå¥åº·æ£€æŸ¥
python3 -m magicbox.monitor.hive.hive_monitor --run=run_all --env=prod
```

### åº”ç”¨ç›‘æ§ç»„åˆ
```bash
# 1. é‡‡é›†å½“å‰è¿è¡Œçš„åº”ç”¨
python3 -m magicbox.periodic.yarn.collect_yarn_app_snapshots --cluster_name=hadoop-cluster --env=prod --states=RUNNING

# 2. é‡‡é›†åº”ç”¨ç»Ÿè®¡
python3 -m magicbox.periodic.yarn.collect_yarn_apps --cluster_name=hadoop-cluster --env=prod

# 3. é‡‡é›†é˜Ÿåˆ—çŠ¶æ€
python3 -m magicbox.periodic.yarn.collect_yarn_queues --cluster_name=hadoop-cluster --env=prod
```

### å­˜å‚¨åˆ†æç»„åˆ
```bash
# 1. HDFSæ•´ä½“å­˜å‚¨
python3 -m magicbox.periodic.hdfs.collect_hdfs_overview --cluster_name=hadoop-cluster --ns_name=ns1 --env=prod

# 2. Hiveæ•°æ®åº“å­˜å‚¨è¯¦æƒ…
python3 -m magicbox.periodic.hdfs.collect_hive_storage --cluster_name=hadoop-cluster --ns_name=ns1 --env=prod
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **ç¯å¢ƒå˜é‡**ï¼šç¡®ä¿ç›¸å…³çš„Hadoopã€Hiveç¯å¢ƒå˜é‡å·²æ­£ç¡®è®¾ç½®
2. **æƒé™**ï¼šç¡®ä¿æ‰§è¡Œç”¨æˆ·æœ‰è¶³å¤Ÿçš„æƒé™è®¿é—®HDFSã€YARNå’ŒHive
3. **Kerberos**ï¼šå¦‚æœå¯ç”¨äº†Kerberosè®¤è¯ï¼Œç¡®ä¿ç¥¨æ®æœ‰æ•ˆ
4. **ç½‘ç»œ**ï¼šç¡®ä¿èƒ½å¤Ÿè®¿é—®ç›¸å…³çš„æœåŠ¡ç«¯ç‚¹
5. **é…ç½®æ–‡ä»¶**ï¼šç¡®ä¿`config/prod/`ç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶æ­£ç¡®é…ç½®

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
python3 -m magicbox.monitor.hive.hive_monitor --run=check_table_storage --env=prod --debug

# æ£€æŸ¥é…ç½®æ–‡ä»¶
ls -la config/prod/

# éªŒè¯ç½‘ç»œè¿æ¥
curl -k https://your-yarn-rm:8088/ws/v1/cluster/info

# æ£€æŸ¥Kerberosç¥¨æ®
klist
```

### æ—¥å¿—ä½ç½®
- æ—¥å¿—ç›®å½•ï¼š`logs/prod/`
- æ—¥å¿—å‘½åï¼š`<ClassName>.log`
- æ—¥å¿—è½®è½¬ï¼š10MB/æ–‡ä»¶ï¼Œä¿ç•™5ä¸ªå¤‡ä»½ 