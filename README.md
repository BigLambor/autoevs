# AutoEVS - å¤§æ•°æ®å¹³å°è‡ªåŠ¨åŒ–è¿ç»´å·¥å…·

AutoEVS æ˜¯ä¸€ä¸ªä¼ä¸šçº§çš„å¤§æ•°æ®å¹³å°è‡ªåŠ¨åŒ–è¿ç»´å·¥å…·é›†ï¼Œä¸“æ³¨äº Hadoop ç”Ÿæ€ç³»ç»Ÿçš„ç›‘æ§ã€æ•°æ®é‡‡é›†å’Œè¿ç»´ç®¡ç†ã€‚é¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„è®¾è®¡ï¼Œæ”¯æŒå¤šç¯å¢ƒéƒ¨ç½²ï¼Œæä¾›ç»Ÿä¸€çš„é…ç½®ç®¡ç†å’Œå®‰å…¨çš„å¯†ç åŠ å¯†æœºåˆ¶ã€‚

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

### ğŸ“Š å…¨é¢ç›‘æ§
- **YARN ç›‘æ§**ï¼šåº”ç”¨çŠ¶æ€ç»Ÿè®¡ã€åº”ç”¨å¿«ç…§é‡‡é›†ã€é˜Ÿåˆ—èµ„æºç›‘æ§ã€é›†ç¾¤èµ„æºç®¡ç†
- **HDFS ç›‘æ§**ï¼šå­˜å‚¨æ¦‚è§ˆã€NameNodeçŠ¶æ€ã€å®¹é‡åˆ†æã€Hiveå­˜å‚¨ç»Ÿè®¡
- **Hive ç›‘æ§**ï¼šè¡¨å­˜å‚¨æ£€æŸ¥ã€åˆ†åŒºå¥åº·ã€æ•°æ®è´¨é‡ã€æŸ¥è¯¢æ€§èƒ½ã€å…ƒæ•°æ®ç®¡ç†
- **Ambari ç›‘æ§**ï¼šé›†ç¾¤æ¸…å•é‡‡é›†ã€æœåŠ¡çŠ¶æ€ç»Ÿè®¡ã€ä¸»æœºå¥åº·ç›‘æ§

### ğŸ—ï¸ ä¼ä¸šçº§æ¶æ„
- **æ¨¡æ¿åŒ–è®¾è®¡**ï¼šç»Ÿä¸€çš„è„šæœ¬åŸºç±»ï¼Œæ ‡å‡†åŒ–å¼€å‘æ¨¡å¼
- **å¤šç¯å¢ƒæ”¯æŒ**ï¼šdev/test/prod ç¯å¢ƒå®Œå…¨éš”ç¦»
- **å¤šå®ä¾‹é…ç½®**ï¼šæ”¯æŒåŒä¸€ç»„ä»¶çš„å¤šä¸ªå®ä¾‹ç®¡ç†
- **ç»Ÿä¸€é…ç½®ç®¡ç†**ï¼šYAML æ ¼å¼é…ç½®ï¼Œæ”¯æŒé…ç½®ç»§æ‰¿å’Œåˆå¹¶

### ğŸ”’ å®‰å…¨ä¸ç¨³å®š
- **å¯†ç åŠ å¯†**ï¼šæ”¯æŒæ•æ„Ÿä¿¡æ¯åŠ å¯†å­˜å‚¨ï¼Œè‡ªåŠ¨è§£å¯†æœºåˆ¶
- **Kerberos é›†æˆ**ï¼šæ”¯æŒå®‰å…¨è®¤è¯ï¼Œä¼ä¸šçº§å®‰å…¨ä¿éšœ
- **å®Œå–„æ—¥å¿—**ï¼šè½®è½¬æ—¥å¿—æœºåˆ¶ï¼Œç»“æ„åŒ–æ—¥å¿—è¾“å‡º
- **é”™è¯¯å¤„ç†**ï¼šç»Ÿä¸€å¼‚å¸¸å¤„ç†ï¼Œé‡è¯•æœºåˆ¶ï¼Œä¼˜é›…é™çº§

### âš¡ è¿ç»´å‹å¥½
- **æ‰¹é‡æ‰§è¡Œ**ï¼šä¸€é”®æ‰§è¡Œæ‰€æœ‰ç›‘æ§ä»»åŠ¡
- **å‘½ä»¤æ ‡å‡†åŒ–**ï¼šç»Ÿä¸€çš„å‘½ä»¤è¡Œæ¥å£å’Œå‚æ•°è§„èŒƒ
- **çµæ´»è°ƒåº¦**ï¼šæ”¯æŒ Crontab å®šæ—¶ä»»åŠ¡ï¼Œé€‚é…å„ç§è°ƒåº¦ç³»ç»Ÿ
- **æ•°æ®æŒä¹…åŒ–**ï¼šMySQL æ•°æ®å­˜å‚¨ï¼Œå®Œæ•´çš„è¡¨ç»“æ„è®¾è®¡

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### åŸºç¡€ç¯å¢ƒ
- **Python**: 3.8+ ï¼ˆæ¨è 3.9+ï¼‰
- **æ“ä½œç³»ç»Ÿ**: Linux/Unixï¼ˆCentOS 7+, Ubuntu 18+ï¼‰ï¼ŒmacOS
- **å†…å­˜**: è‡³å°‘ 4GB ï¼ˆæ¨è 8GB+ï¼‰
- **ç£ç›˜ç©ºé—´**: è‡³å°‘ 2GB å¯ç”¨ç©ºé—´
- **æ•°æ®åº“**: MySQL 5.7+ æˆ– 8.0+

### ç½‘ç»œè®¿é—®
- Hadoop é›†ç¾¤å„ç»„ä»¶çš„ REST API ç«¯å£
- MySQL æ•°æ®åº“è¿æ¥ç«¯å£
- å¦‚å¯ç”¨ Kerberosï¼Œéœ€è®¿é—® KDC æœåŠ¡

### Hadoop ç”Ÿæ€ç‰ˆæœ¬å…¼å®¹æ€§
- **Hadoop**: 2.7+, 3.x
- **Hive**: 2.3+, 3.x
- **HBase**: 1.4+, 2.x
- **Ambari**: 2.7+

## âš¡ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd autoevs

# åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆå¼ºçƒˆæ¨èï¼‰
python3 -m venv venv
source venv/bin/activate  # Linux/Mac

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. å¯†ç åŠ å¯†ï¼ˆæ¨èï¼‰

```bash
# ç”ŸæˆåŠ å¯†ç§å­
python3 tools/generate_seed.py

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå»ºè®®åŠ å…¥ ~/.bashrcï¼‰
export AUTOEVS_CRYPTO_SEED='your_generated_seed'

# åŠ å¯†é…ç½®æ–‡ä»¶ä¸­çš„å¯†ç 
python3 tools/encrypt_passwords.py --config config/prod/mysql.yaml --dry-run
python3 tools/encrypt_passwords.py --config config/prod/mysql.yaml
```

### 3. é…ç½®æ–‡ä»¶è®¾ç½®

```bash
# å¤åˆ¶å¹¶ç¼–è¾‘é…ç½®æ–‡ä»¶
cp config/prod/mysql.yaml.example config/prod/mysql.yaml  # å¦‚æœæœ‰ç¤ºä¾‹æ–‡ä»¶
vim config/prod/mysql.yaml

# é…ç½®å„ç»„ä»¶è¿æ¥ä¿¡æ¯
vim config/prod/hive.yaml
vim config/prod/yarn.yaml
vim config/prod/hdfs.yaml
vim config/prod/ambari.yaml
```

**å…³é”®é…ç½®æ–‡ä»¶è¯´æ˜**ï¼š
```yaml
# mysql.yaml - MySQLæ•°æ®åº“é…ç½®
host: "mysql-server"
port: 3306
username: "autoevs_user"
password: "encrypted_password_here"  # ä½¿ç”¨åŠ å¯†å·¥å…·åŠ å¯†
database: "autoevs"

# hive.yaml - Hiveè¿æ¥é…ç½®ï¼ˆæ”¯æŒå¤šå®ä¾‹ï¼‰
version: "3.1.3"
default_instance: "hive"
instances:
  hive:
    host: "hive-server"
    port: 10000
    metastore_host: "metastore-server"
    metastore_port: 9083
```

### 4. æ•°æ®åº“åˆå§‹åŒ–

```bash
# åˆ›å»ºæ•°æ®åº“å’Œç”¨æˆ·
mysql -u root -p << EOF
CREATE DATABASE autoevs DEFAULT CHARACTER SET utf8mb4;
CREATE USER 'autoevs_user'@'%' IDENTIFIED BY 'your_password';
GRANT ALL PRIVILEGES ON autoevs.* TO 'autoevs_user'@'%';
FLUSH PRIVILEGES;
EOF

# åˆ›å»ºè¡¨ç»“æ„
mysql -u autoevs_user -p autoevs < sql/create_yarn_tables.sql
mysql -u autoevs_user -p autoevs < sql/create_hdfs_storage.sql
mysql -u autoevs_user -p autoevs < sql/create_ambari_tables.sql
```

### 5. éªŒè¯å®‰è£…

```bash
# æµ‹è¯• Hive è¿æ¥
python3 -m magicbox.monitor.hive.hive_monitor --run=check_execution_engine --env=prod --debug

# æµ‹è¯• YARN è¿æ¥
python3 -m magicbox.periodic.yarn.collect_yarn_resources --cluster_name=test-cluster --env=prod

# ä¸€é”®æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
./run_all_magicbox.sh --cluster hadoop-cluster
```

## ğŸ“ é¡¹ç›®æ¶æ„

```
autoevs/
â”œâ”€â”€ ğŸ“‚ config/                    # å¤šç¯å¢ƒé…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ dev/                     # å¼€å‘ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ test/                    # æµ‹è¯•ç¯å¢ƒé…ç½®
â”‚   â””â”€â”€ prod/                    # ç”Ÿäº§ç¯å¢ƒé…ç½®
â”‚       â”œâ”€â”€ hive.yaml           # Hive å¤šå®ä¾‹é…ç½®
â”‚       â”œâ”€â”€ yarn.yaml           # YARN ResourceManager é…ç½®
â”‚       â”œâ”€â”€ hdfs.yaml           # HDFS NameNode é…ç½®
â”‚       â”œâ”€â”€ mysql.yaml          # MySQL æ•°æ®åº“é…ç½®
â”‚       â”œâ”€â”€ ambari.yaml         # Ambari ç®¡ç†å¹³å°é…ç½®
â”‚       â”œâ”€â”€ hbase.yaml          # HBase é…ç½®
â”‚       â””â”€â”€ kerberos.yaml.example # Kerberos è®¤è¯é…ç½®ç¤ºä¾‹
â”‚
â”œâ”€â”€ ğŸ“‚ lib/                       # æ ¸å¿ƒåº“æ¨¡å—
â”‚   â”œâ”€â”€ config/                  # ç»Ÿä¸€é…ç½®ç®¡ç†
â”‚   â”‚   â””â”€â”€ config_manager.py   # é…ç½®ç®¡ç†å™¨ï¼ˆæ”¯æŒåŠ å¯†è§£å¯†ï¼‰
â”‚   â”œâ”€â”€ security/                # å®‰å…¨æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ crypto_utils.py     # å¯†ç åŠ å¯†è§£å¯†å·¥å…·
â”‚   â”‚   â””â”€â”€ field_detector.py   # æ™ºèƒ½å¯†ç å­—æ®µæ£€æµ‹
â”‚   â”œâ”€â”€ hive/                    # Hive å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ yarn/                    # YARN å®¢æˆ·ç«¯  
â”‚   â”œâ”€â”€ hdfs/                    # HDFS å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ mysql/                   # MySQL æ•°æ®åº“å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ ambari/                  # Ambari REST API å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ http/                    # é€šç”¨ HTTP å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ os/                      # æ“ä½œç³»ç»Ÿå‘½ä»¤æ‰§è¡Œ
â”‚   â”œâ”€â”€ kerberos/                # Kerberos è®¤è¯é›†æˆ
â”‚   â””â”€â”€ logger/                  # æ—¥å¿—ç®¡ç†æ¨¡å—
â”‚
â”œâ”€â”€ ğŸ“‚ magicbox/                  # åŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ script_template.py       # è„šæœ¬åŸºç±»æ¨¡æ¿
â”‚   â”œâ”€â”€ monitor/                 # ç›‘æ§æ¨¡å—
â”‚   â”‚   â””â”€â”€ hive/               # Hive æ·±åº¦ç›‘æ§
â”‚   â”‚       â””â”€â”€ hive_monitor.py # è¡¨å¥åº·ã€æ€§èƒ½ã€è´¨é‡æ£€æŸ¥
â”‚   â”œâ”€â”€ periodic/                # å®šæœŸé‡‡é›†ä»»åŠ¡
â”‚   â”‚   â”œâ”€â”€ yarn/               # YARN æ•°æ®é‡‡é›†
â”‚   â”‚   â”‚   â”œâ”€â”€ collect_yarn_apps.py          # åº”ç”¨çŠ¶æ€ç»Ÿè®¡
â”‚   â”‚   â”‚   â”œâ”€â”€ collect_yarn_app_snapshots.py # åº”ç”¨è¯¦ç»†å¿«ç…§
â”‚   â”‚   â”‚   â”œâ”€â”€ collect_yarn_queues.py        # é˜Ÿåˆ—èµ„æºä¿¡æ¯
â”‚   â”‚   â”‚   â””â”€â”€ collect_yarn_resources.py     # é›†ç¾¤èµ„æºç®¡ç†
â”‚   â”‚   â”œâ”€â”€ hdfs/               # HDFS æ•°æ®é‡‡é›†
â”‚   â”‚   â”‚   â”œâ”€â”€ collect_hdfs_overview.py      # HDFS å­˜å‚¨æ¦‚è§ˆ
â”‚   â”‚   â”‚   â””â”€â”€ collect_hive_storage.py       # Hive å­˜å‚¨ç»Ÿè®¡
â”‚   â”‚   â””â”€â”€ ambari/             # Ambari é›†ç¾¤ç®¡ç†
â”‚   â”‚       â”œâ”€â”€ collect_ambari_inventory.py   # é›†ç¾¤æ¸…å•é‡‡é›†
â”‚   â”‚       â””â”€â”€ README.md       # Ambari æ¨¡å—è¯¦ç»†è¯´æ˜
â”‚   â””â”€â”€ trigger/                 # è§¦å‘å™¨æ¨¡å—ï¼ˆé¢„ç•™æ‰©å±•ï¼‰
â”‚
â”œâ”€â”€ ğŸ“‚ sql/                       # æ•°æ®åº“è„šæœ¬
â”‚   â”œâ”€â”€ create_yarn_tables.sql   # YARN ç›‘æ§è¡¨ç»“æ„
â”‚   â”œâ”€â”€ create_hdfs_storage.sql  # HDFS å­˜å‚¨è¡¨ç»“æ„
â”‚   â””â”€â”€ create_ambari_tables.sql # Ambari ç®¡ç†è¡¨ç»“æ„
â”‚
â”œâ”€â”€ ğŸ“‚ tools/                     # è¿ç»´å·¥å…·
â”‚   â”œâ”€â”€ encrypt_passwords.py     # å¯†ç åŠ å¯†å·¥å…·
â”‚   â””â”€â”€ generate_seed.py         # åŠ å¯†ç§å­ç”Ÿæˆå™¨
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                      # è¿è¡Œæ—¶æ—¥å¿—ç›®å½•
â”‚   â”œâ”€â”€ dev/                     # å¼€å‘ç¯å¢ƒæ—¥å¿—
â”‚   â”œâ”€â”€ test/                    # æµ‹è¯•ç¯å¢ƒæ—¥å¿—
â”‚   â””â”€â”€ prod/                    # ç”Ÿäº§ç¯å¢ƒæ—¥å¿—
â”‚
â”œâ”€â”€ run_all_magicbox.sh          # æ‰¹é‡æ‰§è¡Œè„šæœ¬
â”œâ”€â”€ clean_project.sh             # é¡¹ç›®æ¸…ç†è„šæœ¬
â”œâ”€â”€ magicbox_commands.md         # è¯¦ç»†å‘½ä»¤å‚è€ƒ
â”œâ”€â”€ MagicBox_Commands_Standard.md # æ ‡å‡†åŒ–å‘½ä»¤æ‰‹å†Œ
â”œâ”€â”€ README_password_encryption.md # å¯†ç åŠ å¯†ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ requirements.txt             # Python ä¾èµ–åŒ…
â””â”€â”€ README.md                    # é¡¹ç›®æ–‡æ¡£
```

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

### ç›‘æ§æ¨¡å— (magicbox/monitor/)

#### Hive æ·±åº¦ç›‘æ§ (`hive_monitor.py`)
- **è¡¨å­˜å‚¨æ£€æŸ¥**ï¼šå­˜å‚¨æ ¼å¼ã€å‹ç¼©æ–¹å¼ã€æ–‡ä»¶æ ¼å¼éªŒè¯
- **åˆ†åŒºå¥åº·æ£€æŸ¥**ï¼šåˆ†åŒºå®Œæ•´æ€§ã€æ•°æ®åˆ†å¸ƒã€å¼‚å¸¸åˆ†åŒºæ£€æµ‹
- **æ•°æ®è´¨é‡æ£€æŸ¥**ï¼šæ•°æ®ä¸€è‡´æ€§ã€ç©ºå€¼æ£€æµ‹ã€é‡å¤æ•°æ®åˆ†æ
- **æŸ¥è¯¢æ€§èƒ½æ£€æŸ¥**ï¼šæ‰§è¡Œå¼•æ“æ€§èƒ½å¯¹æ¯”ã€æŸ¥è¯¢ä¼˜åŒ–å»ºè®®
- **å…ƒæ•°æ®ç®¡ç†**ï¼šè¡¨ç»“æ„å˜æ›´è·Ÿè¸ªã€æƒé™æ£€æŸ¥

```bash
# æ”¯æŒå¤šç§æ‰§è¡Œå¼•æ“
python3 -m magicbox.monitor.hive.hive_monitor --run=run_all --env=prod --engine=tez
python3 -m magicbox.monitor.hive.hive_monitor --run=check_query_performance --env=prod --engine=spark
```

### å®šæœŸä»»åŠ¡æ¨¡å— (magicbox/periodic/)

#### YARN æ•°æ®é‡‡é›†
- **åº”ç”¨çŠ¶æ€ç»Ÿè®¡** (`collect_yarn_apps.py`)ï¼šå„çŠ¶æ€åº”ç”¨æ•°é‡ç»Ÿè®¡
- **åº”ç”¨è¯¦ç»†å¿«ç…§** (`collect_yarn_app_snapshots.py`)ï¼šåº”ç”¨å®Œæ•´ä¿¡æ¯é‡‡é›†
- **é˜Ÿåˆ—èµ„æºç›‘æ§** (`collect_yarn_queues.py`)ï¼šé˜Ÿåˆ—é…ç½®å’Œä½¿ç”¨æƒ…å†µ
- **é›†ç¾¤èµ„æºç®¡ç†** (`collect_yarn_resources.py`)ï¼šèŠ‚ç‚¹çŠ¶æ€ã€èµ„æºåˆ©ç”¨ç‡

#### HDFS å­˜å‚¨åˆ†æ
- **å­˜å‚¨æ¦‚è§ˆé‡‡é›†** (`collect_hdfs_overview.py`)ï¼šé›†ç¾¤å®¹é‡ã€ä½¿ç”¨ç‡ç»Ÿè®¡
- **Hive å­˜å‚¨ç»Ÿè®¡** (`collect_hive_storage.py`)ï¼šæ•°æ®åº“çº§åˆ«å­˜å‚¨åˆ†æ

#### Ambari é›†ç¾¤ç®¡ç†
- **é›†ç¾¤æ¸…å•é‡‡é›†** (`collect_ambari_inventory.py`)ï¼š
  - è‡ªåŠ¨å­¦ä¹ ç»„ä»¶è§’è‰²åˆ†ç±»
  - ä¸»æœºå’ŒæœåŠ¡æ˜ å°„å…³ç³»
  - é›†ç¾¤å¥åº·çŠ¶æ€ç»Ÿè®¡
  - æ”¯æŒè‡ªå®šä¹‰åˆ†ç±»è§„åˆ™

### å®¢æˆ·ç«¯åº“ (lib/)

#### ç»Ÿä¸€æ¶æ„è®¾è®¡
- **é…ç½®ç®¡ç†** (`config/config_manager.py`)ï¼š
  - å¤šç¯å¢ƒé…ç½®éš”ç¦»
  - å¤šå®ä¾‹é…ç½®æ”¯æŒ
  - é…ç½®ç»§æ‰¿å’Œåˆå¹¶
  - è‡ªåŠ¨å¯†ç è§£å¯†
- **å®‰å…¨æ¨¡å—** (`security/`)ï¼š
  - å¯†ç åŠ å¯†è§£å¯† (`crypto_utils.py`)
  - æ™ºèƒ½å­—æ®µæ£€æµ‹ (`field_detector.py`)
- **ç»Ÿä¸€é”™è¯¯å¤„ç†**ï¼šæ ‡å‡†åŒ–å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
- **Kerberos è®¤è¯**ï¼šä¼ä¸šçº§å®‰å…¨è®¤è¯é›†æˆ

## ğŸ“š ä½¿ç”¨æŒ‡å—

### å‘½ä»¤è¡Œç•Œé¢

æ‰€æœ‰è„šæœ¬éƒ½éµå¾ªç»Ÿä¸€çš„å‘½ä»¤è¡Œè§„èŒƒï¼š

```bash
# åŸºæœ¬æ ¼å¼
python3 -m <æ¨¡å—è·¯å¾„> --å‚æ•°å=å‚æ•°å€¼ [--é€‰é¡¹]

# å¸¸ç”¨å‚æ•°
--env=prod          # ç¯å¢ƒåç§°ï¼ˆdev/test/prodï¼‰
--cluster_name=é›†ç¾¤å # é›†ç¾¤æ ‡è¯†
--debug             # è°ƒè¯•æ¨¡å¼
--help              # å¸®åŠ©ä¿¡æ¯
```

### å¿«é€Ÿå‘½ä»¤å‚è€ƒ

```bash
# =============================================================================
# ğŸ” ç›‘æ§æ£€æŸ¥å‘½ä»¤
# =============================================================================

# Hive å®Œæ•´å¥åº·æ£€æŸ¥
python3 -m magicbox.monitor.hive.hive_monitor --run=run_all --env=prod

# æŒ‡å®šæ‰§è¡Œå¼•æ“çš„æ€§èƒ½æ£€æŸ¥
python3 -m magicbox.monitor.hive.hive_monitor --run=check_query_performance --env=prod --engine=tez

# è¡¨å­˜å‚¨æ ¼å¼æ£€æŸ¥
python3 -m magicbox.monitor.hive.hive_monitor --run=check_table_storage --env=prod --debug

# =============================================================================
# ğŸ“Š æ•°æ®é‡‡é›†å‘½ä»¤
# =============================================================================

# YARN åº”ç”¨çŠ¶æ€é‡‡é›†
python3 -m magicbox.periodic.yarn.collect_yarn_apps --cluster_name=hadoop-cluster --env=prod

# YARN èµ„æºç®¡ç†é‡‡é›†
python3 -m magicbox.periodic.yarn.collect_yarn_resources --cluster_name=hadoop-cluster --env=prod

# HDFS å­˜å‚¨æ¦‚è§ˆé‡‡é›†
python3 -m magicbox.periodic.hdfs.collect_hdfs_overview --cluster_name=hadoop-cluster --ns_name=ns1 --env=prod

# Ambari é›†ç¾¤æ¸…å•é‡‡é›†
python3 -m magicbox.periodic.ambari.collect_ambari_inventory --env=prod

# =============================================================================
# ğŸš€ æ‰¹é‡æ‰§è¡Œå‘½ä»¤
# =============================================================================

# ä½¿ç”¨é»˜è®¤é…ç½®æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
./run_all_magicbox.sh

# æŒ‡å®šé›†ç¾¤æ‰§è¡Œ
./run_all_magicbox.sh --cluster production-cluster

# å®Œå…¨è‡ªå®šä¹‰é…ç½®
./run_all_magicbox.sh --env prod --cluster my-cluster --ns ns2

# æŸ¥çœ‹æ‰§è¡Œå¸®åŠ©
./run_all_magicbox.sh --help
```

### é…ç½®æ–‡ä»¶ç®¡ç†

#### å¤šç¯å¢ƒé…ç½®
```bash
# ç¯å¢ƒé…ç½®ç»“æ„
config/
â”œâ”€â”€ dev/     # å¼€å‘ç¯å¢ƒï¼šè¿æ¥æµ‹è¯•é›†ç¾¤ï¼Œè°ƒè¯•æ—¥å¿—çº§åˆ«
â”œâ”€â”€ test/    # æµ‹è¯•ç¯å¢ƒï¼šè¿æ¥é¢„å‘å¸ƒé›†ç¾¤ï¼Œå®Œæ•´åŠŸèƒ½æµ‹è¯•
â””â”€â”€ prod/    # ç”Ÿäº§ç¯å¢ƒï¼šè¿æ¥ç”Ÿäº§é›†ç¾¤ï¼Œä¼˜åŒ–æ€§èƒ½é…ç½®
```

#### å¤šå®ä¾‹é…ç½®ç¤ºä¾‹
```yaml
# hive.yaml
version: "3.1.3"
default_instance: "hive_primary"

common:
  timeout: 300
  retry_times: 3
  
instances:
  hive_primary:
    host: "hive-primary.company.com"
    port: 10000
    metastore_host: "metastore-primary.company.com"
    metastore_port: 9083
    
  hive_backup:
    host: "hive-backup.company.com"
    port: 10000
    metastore_host: "metastore-backup.company.com"
    metastore_port: 9083
```

### å¯†ç å®‰å…¨ç®¡ç†

#### åŠ å¯†å¯†ç æµç¨‹
```bash
# 1. ç”ŸæˆåŠ å¯†ç§å­ï¼ˆåªéœ€æ‰§è¡Œä¸€æ¬¡ï¼‰
python3 tools/generate_seed.py

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export AUTOEVS_CRYPTO_SEED='your_production_seed'

# 3. é¢„è§ˆè¦åŠ å¯†çš„å­—æ®µ
python3 tools/encrypt_passwords.py --config config/prod/mysql.yaml --dry-run

# 4. åŠ å¯†é…ç½®æ–‡ä»¶
python3 tools/encrypt_passwords.py --config config/prod/mysql.yaml

# 5. æ‰¹é‡åŠ å¯†æ‰€æœ‰é…ç½®
python3 tools/encrypt_passwords.py --pattern "config/prod/*.yaml"
```

## ğŸ› ï¸ è¿ç»´éƒ¨ç½²

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### 1. ç¯å¢ƒå˜é‡é…ç½®
```bash
# ~/.bashrc æˆ– ~/.profile
export AUTOEVS_ENV=prod
export AUTOEVS_CRYPTO_SEED='your_production_seed'
export HADOOP_CONF_DIR=/etc/hadoop/conf
export HIVE_CONF_DIR=/etc/hive/conf

# Kerberos ç¯å¢ƒï¼ˆå¦‚æœéœ€è¦ï¼‰
export KRB5_CONFIG=/etc/krb5.conf
```

#### 2. ç³»ç»ŸæœåŠ¡é…ç½®
```bash
# åˆ›å»ºç³»ç»Ÿç”¨æˆ·
sudo useradd -r -m -s /bin/bash autoevs

# éƒ¨ç½²ä»£ç 
sudo cp -r autoevs /opt/
sudo chown -R autoevs:autoevs /opt/autoevs

# åˆ›å»ºæ—¥å¿—ç›®å½•
sudo mkdir -p /var/log/autoevs
sudo chown autoevs:autoevs /var/log/autoevs
```

#### 3. Crontab å®šæ—¶ä»»åŠ¡
```bash
# ç¼–è¾‘ autoevs ç”¨æˆ·çš„ crontab
sudo -u autoevs crontab -e

# æ·»åŠ å®šæ—¶ä»»åŠ¡
# æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡å®Œæ•´ç›‘æ§
0 * * * * cd /opt/autoevs && ./run_all_magicbox.sh --cluster production-cluster >> /var/log/autoevs/cron.log 2>&1

# æ¯15åˆ†é’Ÿæ‰§è¡Œ YARN èµ„æºç›‘æ§
*/15 * * * * cd /opt/autoevs && python3 -m magicbox.periodic.yarn.collect_yarn_resources --cluster_name=production-cluster --env=prod

# æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ Ambari é›†ç¾¤æ¸…å•é‡‡é›†
0 2 * * * cd /opt/autoevs && python3 -m magicbox.periodic.ambari.collect_ambari_inventory --env=prod

# æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹æ‰§è¡Œæ—¥å¿—æ¸…ç†
0 3 * * 0 cd /opt/autoevs && ./clean_project.sh
```

#### 4. ç›‘æ§å’Œå‘Šè­¦
```bash
# å¥åº·æ£€æŸ¥è„šæœ¬
#!/bin/bash
# health_check.sh

LOG_DIR="/var/log/autoevs"
ERROR_COUNT=$(grep -c "ERROR\|CRITICAL" $LOG_DIR/prod/*.log)

if [ $ERROR_COUNT -gt 0 ]; then
    echo "å‘ç° $ERROR_COUNT ä¸ªé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
    # å‘é€å‘Šè­¦é‚®ä»¶æˆ–é’‰é’‰æ¶ˆæ¯
fi

# æ£€æŸ¥ç£ç›˜ç©ºé—´
DISK_USAGE=$(df /opt/autoevs | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 80 ]; then
    echo "ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡80%: ${DISK_USAGE}%"
fi
```

### Docker éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

```dockerfile
FROM python:3.9-slim

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    default-mysql-client \
    krb5-user \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºåº”ç”¨ç›®å½•
WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºæ—¥å¿—ç›®å½•
RUN mkdir -p logs/prod

# è®¾ç½®æ‰§è¡Œæƒé™
RUN chmod +x run_all_magicbox.sh clean_project.sh

# ç¯å¢ƒå˜é‡
ENV AUTOEVS_ENV=prod

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD python3 -c "from lib.config.config_manager import ConfigManager; ConfigManager()" || exit 1

# é»˜è®¤å‘½ä»¤
CMD ["./run_all_magicbox.sh"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  autoevs:
    build: .
    environment:
      - AUTOEVS_ENV=prod
      - AUTOEVS_CRYPTO_SEED=${AUTOEVS_CRYPTO_SEED}
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
      - /etc/hadoop/conf:/etc/hadoop/conf:ro
      - /etc/hive/conf:/etc/hive/conf:ro
    depends_on:
      - mysql
    restart: unless-stopped

  mysql:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=rootpassword
      - MYSQL_DATABASE=autoevs
      - MYSQL_USER=autoevs_user
      - MYSQL_PASSWORD=autoevs_password
    volumes:
      - mysql_data:/var/lib/mysql
      - ./sql:/docker-entrypoint-initdb.d
    restart: unless-stopped

volumes:
  mysql_data:
```

## ğŸ”§ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„ç›‘æ§åŠŸèƒ½

#### 1. ç»§æ‰¿è„šæœ¬æ¨¡æ¿åŸºç±»
```python
from magicbox.script_template import ScriptTemplate

class MyCustomMonitor(ScriptTemplate):
    def __init__(self, env=None):
        super().__init__(env=env)
        # è‡ªå®šä¹‰åˆå§‹åŒ–é€»è¾‘
        self.my_client = self._create_client()
    
    def _create_client(self):
        """åˆ›å»ºå®¢æˆ·ç«¯è¿æ¥"""
        config = self.get_component_config("my_component")
        # è¿”å›å®¢æˆ·ç«¯å®ä¾‹
        
    def check_something(self, **kwargs):
        """è‡ªå®šä¹‰æ£€æŸ¥åŠŸèƒ½"""
        self.logger.info("å¼€å§‹æ‰§è¡Œè‡ªå®šä¹‰æ£€æŸ¥")
        try:
            # å®ç°æ£€æŸ¥é€»è¾‘
            result = {"status": "success", "data": "æ£€æŸ¥ç»“æœ"}
            self.logger.info("æ£€æŸ¥å®Œæˆ")
            return result
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥å¤±è´¥: {str(e)}")
            raise
```

#### 2. é…ç½®æ–‡ä»¶è®¾è®¡
```yaml
# config/prod/my_component.yaml
version: "1.0"
default_instance: "primary"

common:
  timeout: 300
  retry_times: 3
  
instances:
  primary:
    host: "component-server"
    port: 8080
    username: "admin"
    password: "encrypted_password"
```

#### 3. å‘½ä»¤è¡Œæ¥å£
```python
def parse_args():
    parser = argparse.ArgumentParser(description='è‡ªå®šä¹‰ç›‘æ§è„šæœ¬')
    parser.add_argument('--run', required=True, help='æ‰§è¡Œçš„å‡½æ•°å')
    parser.add_argument('--env', choices=['dev', 'test', 'prod'], help='ç¯å¢ƒ')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    return parser.parse_args()

def main():
    args = parse_args()
    script = MyCustomMonitor(env=args.env)
    
    if args.debug:
        script.logger.setLevel(logging.DEBUG)
    
    result = script.run_function(args.run)
    script.logger.info(f"æ‰§è¡Œç»“æœ: {result}")

if __name__ == "__main__":
    main()
```

### æ•°æ®åº“è¡¨è®¾è®¡è§„èŒƒ

```sql
-- è¡¨å‘½åè§„èŒƒï¼š{ç»„ä»¶}_{åŠŸèƒ½}_{ç±»å‹}
CREATE TABLE IF NOT EXISTS my_component_monitor_stats (
    id BIGINT AUTO_INCREMENT PRIMARY KEY COMMENT 'ä¸»é”®ID',
    cluster_name VARCHAR(100) NOT NULL COMMENT 'é›†ç¾¤åç§°',
    collect_time DATETIME NOT NULL COMMENT 'æ•°æ®é‡‡é›†æ—¶é—´',
    insert_time DATETIME NOT NULL COMMENT 'æ•°æ®æ’å…¥æ—¶é—´',
    
    -- ä¸šåŠ¡å­—æ®µ
    metric_name VARCHAR(100) NOT NULL COMMENT 'æŒ‡æ ‡åç§°',
    metric_value DECIMAL(15,2) NOT NULL COMMENT 'æŒ‡æ ‡å€¼',
    
    -- ç´¢å¼•è®¾è®¡
    INDEX idx_cluster_collect_time (cluster_name, collect_time),
    INDEX idx_metric_name (metric_name),
    INDEX idx_insert_time (insert_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='è‡ªå®šä¹‰ç»„ä»¶ç›‘æ§ç»Ÿè®¡è¡¨';
```

### ä»£ç è§„èŒƒå’Œæœ€ä½³å®è·µ

#### 1. æ—¥å¿—è®°å½•è§„èŒƒ
```python
# æ ‡å‡†æ—¥å¿—çº§åˆ«ä½¿ç”¨
self.logger.debug("è°ƒè¯•ä¿¡æ¯ï¼šå˜é‡å€¼ä¸º {value}")
self.logger.info("æ­£å¸¸æ“ä½œï¼šå¼€å§‹æ‰§è¡ŒæŸé¡¹ä»»åŠ¡")
self.logger.warning("è­¦å‘Šä¿¡æ¯ï¼šé…ç½®é¡¹ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")
self.logger.error("é”™è¯¯ä¿¡æ¯ï¼šæ“ä½œå¤±è´¥ï¼Œé”™è¯¯åŸå› ")
self.logger.critical("ä¸¥é‡é”™è¯¯ï¼šç³»ç»Ÿæ— æ³•ç»§ç»­è¿è¡Œ")

# åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
self.logger.info(f"å¼€å§‹å¤„ç†é›†ç¾¤ {cluster_name} çš„ {component} ç»„ä»¶")
```

#### 2. å¼‚å¸¸å¤„ç†è§„èŒƒ
```python
def robust_operation(self):
    """å¥å£®çš„æ“ä½œç¤ºä¾‹"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # æ‰§è¡Œæ“ä½œ
            result = self._do_operation()
            self.logger.info("æ“ä½œæ‰§è¡ŒæˆåŠŸ")
            return result
        except ConnectionError as e:
            self.logger.warning(f"è¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
            if attempt == max_retries - 1:
                self.logger.error("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œæ”¾å¼ƒæ“ä½œ")
                raise
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        except Exception as e:
            self.logger.error(f"æœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
            raise
```

#### 3. é…ç½®éªŒè¯
```python
def validate_and_get_config(self):
    """é…ç½®éªŒè¯ç¤ºä¾‹"""
    required_keys = ['host', 'port', 'username', 'password']
    
    if not self.validate_config('my_component', required_keys):
        raise ValueError("é…ç½®éªŒè¯å¤±è´¥")
    
    config = self.get_component_config('my_component')
    
    # é¢å¤–çš„ä¸šåŠ¡éªŒè¯
    if config['port'] < 1 or config['port'] > 65535:
        raise ValueError(f"æ— æ•ˆçš„ç«¯å£å·: {config['port']}")
    
    return config
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è¯Šæ–­

#### 1. è¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
telnet yarn-resourcemanager 8088
curl -k "https://ambari-server:8080/api/v1/clusters"

# æ£€æŸ¥ Kerberos è®¤è¯
klist -v
kinit username@REALM

# æ£€æŸ¥ Hadoop é…ç½®
hadoop classpath
hdfs dfsadmin -report
```

#### 2. é…ç½®é—®é¢˜
```bash
# éªŒè¯é…ç½®æ–‡ä»¶è¯­æ³•
python3 -c "
import yaml
with open('config/prod/hive.yaml') as f:
    config = yaml.safe_load(f)
    print('é…ç½®æ–‡ä»¶è¯­æ³•æ­£ç¡®')
    print(f'é…ç½®å†…å®¹: {config}')
"

# æ£€æŸ¥å¯†ç è§£å¯†
python3 -c "
from lib.config.config_manager import ConfigManager
cm = ConfigManager('prod')
config = cm.get_component_config('mysql')
print('MySQLé…ç½®åŠ è½½æˆåŠŸ')
"
```

#### 3. æƒé™é—®é¢˜
```bash
# æ£€æŸ¥æ–‡ä»¶æƒé™
ls -la config/prod/
ls -la logs/prod/

# æ£€æŸ¥æ•°æ®åº“æƒé™
mysql -u autoevs_user -p -e "SHOW GRANTS FOR CURRENT_USER;"

# æ£€æŸ¥ HDFS æƒé™
hdfs dfs -ls /user/$(whoami)
```

### è°ƒè¯•æŠ€å·§

#### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—
```bash
# å•ä¸ªè„šæœ¬è°ƒè¯•
python3 -m magicbox.monitor.hive.hive_monitor --run=check_table_storage --env=dev --debug

# ä¿®æ”¹æ—¥å¿—çº§åˆ«
export AUTOEVS_LOG_LEVEL=DEBUG
```

#### 2. é€æ­¥éªŒè¯
```bash
# 1. éªŒè¯åŸºç¡€è¿æ¥
python3 -c "
from lib.hive.hive_client import HiveClient
from lib.config.config_manager import ConfigManager

cm = ConfigManager('prod')
config = cm.get_component_config('hive')
client = HiveClient(config)
print('Hive è¿æ¥æµ‹è¯•æˆåŠŸ')
"

# 2. éªŒè¯ SQL æ‰§è¡Œ
python3 -c "
# ... è¿æ¥ä»£ç  ...
result = client.execute_sql('SHOW DATABASES')
print(f'æ•°æ®åº“åˆ—è¡¨: {result}')
"
```

#### 3. æ€§èƒ½åˆ†æ
```bash
# ä½¿ç”¨ time å‘½ä»¤æµ‹é‡æ‰§è¡Œæ—¶é—´
time python3 -m magicbox.monitor.hive.hive_monitor --run=run_all --env=prod

# ä½¿ç”¨ cProfile è¿›è¡Œæ€§èƒ½åˆ†æ
python3 -m cProfile -o profile.stats -m magicbox.monitor.hive.hive_monitor --run=check_query_performance --env=prod

# åˆ†ææ€§èƒ½ç»“æœ
python3 -c "
import pstats
p = pstats.Stats('profile.stats')
p.sort_stats('cumulative').print_stats(20)
"
```

### æ—¥å¿—åˆ†æ

#### 1. å¿«é€Ÿé”™è¯¯æ£€æŸ¥
```bash
# æŸ¥çœ‹æœ€è¿‘çš„é”™è¯¯
grep -i "error\|exception\|failed" logs/prod/*.log | tail -20

# æŒ‰æ—¶é—´è¿‡æ»¤é”™è¯¯
grep -i error logs/prod/HiveMonitor.log | grep "$(date '+%Y-%m-%d')"

# ç»Ÿè®¡é”™è¯¯ç±»å‹
grep -i error logs/prod/*.log | cut -d':' -f3- | sort | uniq -c | sort -nr
```

#### 2. æ€§èƒ½ç›‘æ§
```bash
# æŸ¥çœ‹æ‰§è¡Œæ—¶é—´
grep "æ‰§è¡Œæ—¶é—´\|execution time" logs/prod/*.log

# ç›‘æ§å†…å­˜ä½¿ç”¨
grep -i "memory\|å†…å­˜" logs/prod/*.log

# å®æ—¶ç›‘æ§æ—¥å¿—
tail -f logs/prod/*.log | grep -i "error\|warning\|info"
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. æ•°æ®åº“ä¼˜åŒ–
```sql
-- æ·»åŠ å¿…è¦çš„ç´¢å¼•
CREATE INDEX idx_collect_time_cluster ON yarn_application_stats(collect_time, cluster_name);
CREATE INDEX idx_application_id_collect_time ON yarn_application_snapshots(application_id, collect_time);

-- å®šæœŸæ¸…ç†å†å²æ•°æ®
DELETE FROM yarn_application_snapshots WHERE collect_time < DATE_SUB(NOW(), INTERVAL 30 DAY);

-- ä¼˜åŒ–è¡¨ç»“æ„
OPTIMIZE TABLE yarn_application_stats;
ANALYZE TABLE yarn_application_snapshots;
```

### 2. åº”ç”¨çº§ä¼˜åŒ–
```python
# è¿æ¥æ± é…ç½®
mysql_config = {
    'pool_size': 10,
    'max_overflow': 20,
    'pool_pre_ping': True,
    'pool_recycle': 3600
}

# æ‰¹é‡æ’å…¥ä¼˜åŒ–
def batch_insert_data(self, table_name, data_list, batch_size=1000):
    """æ‰¹é‡æ’å…¥æ•°æ®"""
    for i in range(0, len(data_list), batch_size):
        batch = data_list[i:i + batch_size]
        self.mysql_client.batch_insert(table_name, batch)
```

### 3. ç³»ç»Ÿçº§ä¼˜åŒ–
```bash
# è°ƒæ•´ Python åƒåœ¾å›æ”¶
export PYTHONHASHSEED=0
export PYTHONDONTWRITEBYTECODE=1

# å¢åŠ æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
ulimit -n 65536

# ä¼˜åŒ– MySQL è¿æ¥æ•°
# my.cnf
[mysqld]
max_connections = 500
innodb_buffer_pool_size = 2G
query_cache_size = 128M
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å¼€å‘ç¯å¢ƒè®¾ç½®
```bash
# 1. Fork é¡¹ç›®å¹¶å…‹éš†
git clone https://github.com/your-username/autoevs.git
cd autoevs

# 2. åˆ›å»ºå¼€å‘åˆ†æ”¯
git checkout -b feature/new-feature

# 3. å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-dev.txt  # å¦‚æœæœ‰å¼€å‘ä¾èµ–

# 4. é…ç½®å¼€å‘ç¯å¢ƒ
cp config/dev/mysql.yaml.example config/dev/mysql.yaml
# ç¼–è¾‘é…ç½®æ–‡ä»¶...

# 5. è¿è¡Œæµ‹è¯•
python3 -m pytest tests/  # å¦‚æœæœ‰æµ‹è¯•ç”¨ä¾‹
```

### ä»£ç æäº¤è§„èŒƒ
```bash
# æäº¤ä¿¡æ¯æ ¼å¼
git commit -m "ç±»å‹(èŒƒå›´): ç®€çŸ­æè¿°

è¯¦ç»†æè¿°ï¼ˆå¯é€‰ï¼‰

å…³è”é—®é¢˜: #123"

# ç±»å‹è¯´æ˜
feat:     æ–°åŠŸèƒ½
fix:      Bug ä¿®å¤
docs:     æ–‡æ¡£æ›´æ–°
style:    ä»£ç æ ¼å¼è°ƒæ•´
refactor: é‡æ„
test:     æµ‹è¯•ç›¸å…³
chore:    æ„å»º/å·¥å…·é“¾ç›¸å…³
```

### Pull Request æµç¨‹
1. ç¡®ä¿ä»£ç é€šè¿‡æ‰€æœ‰æµ‹è¯•
2. æ›´æ–°ç›¸å…³æ–‡æ¡£
3. æ·»åŠ å˜æ›´æ—¥å¿—æ¡ç›®
4. åˆ›å»º Pull Request
5. ç­‰å¾…ä»£ç å®¡æŸ¥

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ“ æ”¯æŒä¸ç¤¾åŒº

### è·å–å¸®åŠ©
- **GitHub Issues**: [æäº¤é—®é¢˜å’Œ Bug æŠ¥å‘Š](https://github.com/your-org/autoevs/issues)
- **è®¨è®ºåŒº**: [åŠŸèƒ½å»ºè®®å’Œä½¿ç”¨è®¨è®º](https://github.com/your-org/autoevs/discussions)
- **Wiki**: [è¯¦ç»†æ–‡æ¡£å’ŒFAQ](https://github.com/your-org/autoevs/wiki)

### å¿«é€Ÿé“¾æ¥
- ğŸ“– [è¯¦ç»†å‘½ä»¤å‚è€ƒ](magicbox_commands.md)
- ğŸ”’ [å¯†ç åŠ å¯†æŒ‡å—](README_password_encryption.md)
- ğŸš€ [æ ‡å‡†åŒ–å‘½ä»¤æ‰‹å†Œ](MagicBox_Commands_Standard.md)
- ğŸ”§ [Ambari æ¨¡å—è¯´æ˜](magicbox/periodic/ambari/README.md)

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹æ€»ç»“

```bash
# ğŸš€ 30ç§’å¿«é€Ÿå¯åŠ¨
git clone <repository-url> && cd autoevs
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# ğŸ“ é…ç½®æ•°æ®åº“è¿æ¥
vim config/prod/mysql.yaml

# ğŸ—„ï¸ åˆå§‹åŒ–æ•°æ®åº“
mysql -u user -p database < sql/create_yarn_tables.sql

# â–¶ï¸ æ‰§è¡Œç›‘æ§ä»»åŠ¡
./run_all_magicbox.sh --cluster your-cluster-name

# ğŸ‰ å¼€å§‹ç›‘æ§æ‚¨çš„å¤§æ•°æ®å¹³å°ï¼
```

**AutoEVS** - è®©å¤§æ•°æ®å¹³å°è¿ç»´æ›´ç®€å•ã€æ›´æ™ºèƒ½ã€æ›´å¯é ï¼ 